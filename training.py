# -*- coding: utf-8 -*-
"""TrainingOnlyVer2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cmgqsNTS8qiqrKoq-65VROnD3kOleTv7
"""
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import Dataset
import torch
import torch.nn.functional as F  # Parameterless functions, like (some) activation functions
from torch import optim  # For optimizers like SGD, Adam, etc.
from torch import nn  # All neural network modules
from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.
from tqdm import tqdm  # For nice progress bar!
import wandb
import torch
import torchvision
import time
from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.
from tqdm import tqdm  # For nice progress bar!
import numpy as np
import pandas as pd
import os
import torch.nn.init as init

# @title Datastore Class


class Singleton(type):
    _instances = {}

    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)
        return cls._instances[cls]


class Datastore(metaclass=Singleton):

    def __init__(self):
        self.data = {}

    def get_size(self):
        return len(self.data)

    def get_data(self, annotations, root_dir):

        size = len(annotations.index)

        if len(self.data) != size:
            print("Preloading dataset")
            for i in tqdm(range(0, size)):

                learnData = torch.Tensor()
                for j in range(5):
                    data_path = os.path.join(root_dir, 'GramsVer2', annotations.iloc[i, 0] + str(j))
                    learnData = torch.cat((learnData, torch.load(data_path).flatten()), 0)
                    # learnData.append(torch.load(data_path).flatten())

                data_path = os.path.join(root_dir, 'CoreColors', annotations.iloc[i, 0] + "_Colors.npy")

                # learnData.append(np.load(data_path).flatten())
                learnData = torch.cat((learnData, torch.from_numpy(np.load(data_path).flatten())), 0)
                self.data[i] = learnData
                # print(learnData)

            # print("data already preloaded, returning")
        return self.data

    def reset(self):
        self.data = {}


# @title Dataset Class


class BlenderSuperShaderRendersDataset(Dataset):
    def __init__(self, param_dir, gram_directory, transform=None, add_key_colors_to_input=False, prefetched_path=None, safe_or_load_prefetch=None):
        self.param_dir = param_dir
        self.gram_directory = gram_directory
        self.transform = transform
        # self.data_store = Datastore()
        self.add_key_colors_to_input = add_key_colors_to_input
        self.gram_path_cols = []
        self.dataset = None
        self.feature_mask = None

        self.num_params = 41


        if prefetched_path is None:
            self.init_dataframe()
        elif safe_or_load_prefetch == "safe":
            self.init_dataframe(save_df_to=prefetched_path)
        elif safe_or_load_prefetch == "load":
            self.dataset = pd.read_csv(prefetched_path, header=[0, 1])
        else:
            print("Invalid save_or_load_prefetch parameter. Use 'safe' or 'load'")
            raise ValueError("Invalid save_or_load_prefetch parameter. Use 'safe' or 'load'")


    def init_dataframe(self, save_df_to=None):
        samples = set([x.split('_')[0] for x in os.listdir(self.gram_directory)])
        self.gram_path_cols = [f"gra_{i}_path" for i in range(5)]

        mult_idx_tuples = []

        rows = []
        for sample in tqdm(samples, desc="Loading samples into dataset"):
            row = pd.read_csv(os.path.join(self.param_dir, f"parameters_frame_{int(sample)}.txt"), delimiter=',', header=0, dtype=np.float32)

            if mult_idx_tuples == []:
                column_names = row.columns
                column_categories = ['frame'] + ['parameters'] * self.num_params + ['key_colors'] * 9
                mult_idx_tuples = list(zip(column_categories, column_names)) + [('gram_paths', p_col) for p_col in self.gram_path_cols]

            for i in range(5):
                row[self.gram_path_cols[i]] = os.path.join(self.gram_directory, f"{sample}_{i}")

            rows.append(row)

        self.dataset = pd.concat(rows)
        self.dataset['frame'] = self.dataset['frame'].astype(int)
        multi_index = pd.MultiIndex.from_tuples(mult_idx_tuples)
        self.dataset.columns = multi_index

        if save_df_to is not None:
            self.dataset.to_csv(save_df_to, index=False)

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, index):

        dataset_row = self.dataset.iloc[index]
        input_grams = [torch.load(gram_filename) for gram_filename in dataset_row['gram_paths']]
        input_gram_diags = [gram[np.triu_indices(gram.shape[0], k=1)] for gram in input_grams]
        input_grams_concat = torch.cat(input_gram_diags)

        params = dataset_row['parameters'].values.astype(np.float32)

        if self.add_key_colors_to_input:
            params = np.concatenate((params, dataset_row['key_colors'].values))

        if self.feature_mask is not None:
            input_grams_concat = input_grams_concat[self.feature_mask]

        params = torch.tensor(params)

        return (input_grams_concat, params)

    def set_feature_mask(self, mask):
        self.feature_mask = mask


def check_accuracy(loader, model, verbose=False):
    with torch.no_grad():
        diff = 0
        count = 0
        for data, labels in loader:
            # print(data)
            data = data.to(device=device)
            labels = labels.to(device=device)
            # data = data.reshape(data.shape[0], -1)

            scores = model(data.float())

            diff += torch.mean(torch.absolute(scores - labels))
            if verbose:
                # pdb.set_trace()
                print("\033[95m" + str(torch.mean(data)) + " - " + str(torch.median(data)))
                print("\033[93m" + str(scores.float()))
                print("\x1B[37m" + str(labels.float()))
            # print(diff)
            count += 1

    return 1 - (diff / count)



class NN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(NN, self).__init__()
        # Our first linear layer take input_size, in this case 348170 node (!!!) compressing that to 300 sucks. how to deal with that much data?
        self.fc1 = nn.Linear(input_size, 3000)
        self.fc2 = nn.Linear(3000, 1000)
        self.fc3 = nn.Linear(1000, 1000)
        self.fc4 = nn.Linear(1000, 100)
        self.fc5 = nn.Linear(100, 100)
        self.fc6 = nn.Linear(100, 100)
        # self.fc7 = nn.Linear(100, 100)
        # self.fc8 = nn.Linear(100, 100)
        self.fc9 = nn.Linear(100, num_classes)
        self.apply(self.init_weights)


    def init_weights(self, m):
        if isinstance(m, nn.Linear):
            # He initialization for ReLU activation
            init.kaiming_uniform_(m.weight, nonlinearity='relu')
            if m.bias is not None:
                init.constant_(m.bias, 0)

    def forward(self, x):
        """
        x here is the mnist images and we run it through fc1, fc2 that we created above.
        we also add a ReLU activation function in between and for that (since it has no parameters)
        I recommend using nn.functional (F)
        """
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        x = F.relu(x)
        x = self.fc3(x)
        x = F.relu(x)
        x = self.fc4(x)
        x = F.relu(x)
        x = self.fc5(x)
        x = F.relu(x)
        x = self.fc6(x)
        x = F.relu(x)
        # x = self.fc7(x)
        # x = F.relu(x)
        # x = self.fc8(x)
        # x = F.relu(x)
        x = self.fc9(x)
        x = torch.sigmoid(x)
        return x


# @title Train

import time


def train():

    save_path = os.path.join(root_dir, "Models", wandb_run.id)
    os.makedirs(save_path, exist_ok=True)

    best_loss = float('inf')
    for epoch in range(config.num_epochs):

        for batch_idx, (data, targets) in (enumerate(train_loader)):
            # Get data to cuda if possible
            data = data.to(device=device)
            targets = targets.to(device=device)

            # Get to correct shape
            # data = data.reshape(data.shape[0], -1)

            # forward
            predictions = model(data.float())
            loss = criterion(predictions, targets.float())

            wandb.log({"loss": loss})

            # backward
            optimizer.zero_grad()
            loss.backward()

            # gradient descent or adam step
            optimizer.step()


        if loss.item() < best_loss:
            best_loss = loss.item()
            try:
                torch.save(model, os.path.join(save_path, "best.model"))
            except Exception as e:
                print(f"Saving model didn't work: {e}")

        if (epoch % 20 == 0):
            print(str(time.ctime()) + "  -  epoch: " + str(epoch))
            acc = check_accuracy(test_loader, model)

            trainAcc = check_accuracy(train_loader, model)

            wandb.log({"Train Acc": trainAcc, "Test Acc": acc})
            print(f"Accuracy on test/train set: {acc :.2f}/{trainAcc :.2f}")

            torch.cuda.empty_cache()

        if (epoch % 400 == 0):
            try:
                torch.save(model, os.path.join(save_path, f"{str(epoch)}.model"))
            except Exception as e:
                print(f"saving model didnt work: {e}")

        scheduler.step()
        wandb.log({"lr": scheduler.get_last_lr()[0]})

    print(f"Accuracy on training set: {check_accuracy(train_loader, model):.2f}")
    print(f"Accuracy on test set: {check_accuracy(test_loader, model):.2f}")



def get_feature_importance(dataset):
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.multioutput import MultiOutputRegressor

    # Assuming `X` is your input matrix with shape [n_samples, 300000] and `y` are your targets

    # from cuml.ensemble import RandomForestRegressor as cuRF


    feature_importances = []

    num_checked = 0
    for data, targets in tqdm(DataLoader(dataset, batch_size=100, shuffle=True, num_workers=4), total=(len(dataset) // 1000) + 1):
        # model = cuRF(n_estimators=100)
        # model.fit(data.numpy(), targets.numpy())
        # feature_importances.append(model.predict(data.numpy()))



        model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, n_jobs=-1))
        model.fit(data.numpy(), targets.numpy())
        feature_importance = model.estimators_[0].feature_importances_
        feature_importances.append(feature_importance)
        num_checked += len(data)

        if num_checked > 10000:
            break

    # Average the feature importances across all batches
    return np.mean(feature_importances, axis=0)


# @title Mean Squared Log-scaled Error Loss
import pdb


class MSLELoss(nn.Module):
    def __init__(self, logPart=15):
        super().__init__()
        self.mse = nn.MSELoss()
        self.a = logPart

    def forward(self, pred, actual):
        ret = self.mse(pred, actual) + self.a * (self.mse(torch.log(pred + 0.0000001), torch.log(actual + 0.0000001)))
        return ret


# @title Here is the learning part
import matplotlib.pyplot as plt

# Set device cuda for GPU if it's available otherwise run on the CPU
if __name__ == '__main__':

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("running on " + str(device))

    wandb_run = wandb.init(project='newDataset2024', entity='liquidmasl')

    # input_size = 304416  # Number of input pixels, this is just the grams and (optionally) 3 key colors
    input_size = 50000
    num_classes = 41  # number of parameters
    init_lr = 0.0001
    lr_step_size = 100
    lr_gamma = 0.1
    batch_size = 4
    num_epochs = 5000
    loss_log_part = 20

    # Load Training and Test data
    # train_dataset = datasets.MNIST(root="dataset/", train=True, transform=transforms.ToTensor(), download=True)
    # test_dataset = datasets.MNIST(root="dataset/", train=False, transform=transforms.ToTensor(), download=True)

    root_dir = R'/data'

    dataset = BlenderSuperShaderRendersDataset(param_dir=r'/app/data/Frames',
                                               gram_directory=r'/app/data/grams/normalised',
                                               prefetched_path=r'/app/data/prefetched_dataset.csv',
                                               safe_or_load_prefetch='load')

    feature_importance = get_feature_importance(dataset)

    np.save(os.path.join(root_dir, "feature_importance.npy"), feature_importance)

    highest_or_non_zero_mask = feature_importance > 0.0001

    non_zero_indices = np.where(highest_or_non_zero_mask > 0)[0]
    non_zero_importances = highest_or_non_zero_mask[non_zero_indices]

    # Sort the non-zero importances and get indices in descending order of importance
    sorted_indices = np.argsort(non_zero_importances)[::-1]

    # Select the top n importances or all if there are less than n
    top_indices = sorted_indices[:min(input_size, len(sorted_indices))]

    # Get the actual indices of the top features
    top_feature_indices = non_zero_indices[top_indices]

    dataset.set_feature_mask(top_feature_indices)
    input_size = len(top_feature_indices)

    print(input_size)

    # randomly split training and testing set
    # train_dataset, test_dataset = torch.utils.data.Subset(dataset, range(0, 2)), torch.utils.data.Subset(dataset, [10])
    # train_dataset, test_dataset = torch.utils.data.random_split(dataset, [9900, 99])
    train_dataset, test_dataset = torch.utils.data.Subset(dataset, range(0, 10)), torch.utils.data.Subset(dataset, range(101, 111))


    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4,
                               pin_memory=True, persistent_workers=True)
    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, num_workers=4,
                               pin_memory=True, persistent_workers=True)

    # Initialize network
    model = NN(input_size=input_size, num_classes=num_classes).to(device)
    wandb.watch(model)

    # Loss and optimizer
    # criterion = nn.CrossEntropyLoss() # cross entropy loss is used for probability outputs, so this might not be optimal at all.
    # criterion = nn.MSELoss()
    # criterion = nn.L1Loss()
    criterion = MSLELoss(loss_log_part)
    optimizer = optim.Adam(model.parameters(), lr=init_lr)
    scheduler = StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)

    print(f"Accuracy on training set: {check_accuracy(train_loader, model):.2f}")
    print(f"Accuracy on test set: {check_accuracy(test_loader, model):.2f}")

    config = wandb.config

    # Hyperparameters of our neural network which depends on the dataset, and
    # also just experimenting to see what works well (learning rate for example).
    config.input_size = input_size  # Number of input pixels, this is just the grams and 3 key colors
    config.num_classes = num_classes  # number of parameters
    config.init_lr = init_lr
    config.lr_step_size = lr_step_size
    config.lr_gamma = lr_gamma
    config.batch_size = batch_size
    config.num_epochs = num_epochs
    config.loss_log_part = loss_log_part

    config.criterion = str(criterion)
    config.NN = str(model)

    train()

# Commented out IPython magic to ensure Python compatibility.
# %debug
#
#
# import time
# from tqdm import tqdm
#
#
# def train(data_loader):
#     start = time.time()
#     for _ in tqdm(range(10)):
#         for x in data_loader:
#             pass
#     end = time.time()
#     return end - start
#
#
# if __name__ == '__main__':
#     train_dataset = torchvision.datasets.FashionMNIST(
#         root=".", train=True, download=True,
#         transform=torchvision.transforms.ToTensor()
#     )
#
#     batch_size = 32
#     train_loader1 = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,
#                                                 pin_memory=True, num_workers=0)
#     train_loader2 = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,
#                                                 pin_memory=True, num_workers=8)
#     train_loader3 = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,
#                                                 pin_memory=True, num_workers=8, persistent_workers=True)
#     train_loader4 = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,
#                                                 pin_memory=True, num_workers=10, persistent_workers=True)
#
#     print(train(train_loader1))
#     print(train(train_loader2))
#     print(train(train_loader3))
#     print(train(train_loader4))
#
#
#

def test_train(data_loader):
    start = time.time()
    for _ in tqdm(range(10)):
        for x in data_loader:
            pass
    end = time.time()
    return end - start


if __name__ == 'dfg__main__':
    batch_size = 64

    root_dir = R'/data/'
    dataset = BlenderSuperShaderRendersDataset(param_dir=r'/app/data/Frames', gram_directory=r'/app/data/grams/normalised', prefetched_path=r'/app/data/prefetched_dataset.csv', safe_or_load_prefetch='load')
    train_num = 100
    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_num, len(dataset) - 100])

    train_loader1 = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0,
                               pin_memory=True)
    train_loader2 = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4,
                               pin_memory=True, persistent_workers=True)
    train_loader3 = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=8,
                               pin_memory=True, persistent_workers=True)

    print(test_train(train_loader1))
    print(test_train(train_loader2))
    print(test_train(train_loader3))
#
# # Commented out IPython magic to ensure Python compatibility.
# # %debug
#
#
# # @title Dataset Class without datastore singletop cause threading
#
# import os
# import pandas as pd
# import torch
# from torch.utils.data import Dataset
# import numpy as np
#
#
# # from skimage import io
#
# class smallShaderDataset(Dataset):
#     def __init__(self, csv_file, root_dir, transform=None):
#         self.annotations = pd.read_csv(os.path.join(root_dir, csv_file))
#         self.root_dir = root_dir
#         self.transform = transform
#         # self.data_store = Datastore()
#         # self.data = {}
#
#         # print("Preloading dataset")
#         # for i in tqdm(range(0,len(self.annotations.index))):
#         #  data_path = os.path.join(root_dir,'LearnDataCombined', self.annotations.iloc[i,0] + ".npy")
#         #  self.data[i] = np.load(data_path).astype(float)
#
#     def __len__(self):
#         return len(self.annotations)
#
#     def __getitem__(self, index):
#         # if self.data_store is None:
#         #   data_path = os.path.join(self.root_dir,'LearnDataCombined', self.annotations.iloc[index,0] + ".npy")
#         #   input = np.load(data_path)
#         # else:
#         #   input = self.data_store.get_data(annotations=self.annotations,root_dir=self.root_dir)[index]
#
#         # input = self.data[index]
#         data_path = os.path.join(self.root_dir, 'LearnDataCombined', self.annotations.iloc[index, 0] + ".npy")
#         input = np.load(data_path)
#
#         parameters = self.annotations.iloc[index, 1:]
#         parameters = np.array([parameters], dtype=float).flatten()
#         input = np.array(input, dtype=float)
#
#         sample = {'input': input, 'parameters': parameters}
#
#         # Maybe think about transforms for data augmentation. Not sure if
#         # augmentation is possible on gram matrices. maybe they have to be done before the gram calculation is done
#         # if self.transform:
#         #  sample = self.transform(sample)
#
#         # sample.ToTensor()
#
#         return input, parameters
#         # return sample
#
#
# import torch
# from torch import nn  # All neural network modules
# from torch import optim  # For optimizers like SGD, Adam, etc.
#
# criterion = nn.MSELoss()
#
# x = torch.randn(10, 10)
# y = torch.randn(10, 10).double()
#
# loss = criterion(x, y)
# print(loss)
#
#
# class MSLELoss(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.mse = nn.MSELoss()
#
#     def forward(self, pred, actual):
#         return self.mse(pred, actual)
#
#
# my_criterion = MSLELoss()
# loss = my_criterion(x, y)
# print(loss)
#
# x = torch.randn(2, 3)
# y = torch.randn(5, 7)
#
# torch.cat((x.flatten(), y.flatten()))
